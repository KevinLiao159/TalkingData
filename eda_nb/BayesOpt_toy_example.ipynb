{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TalkingData AdTracking Fraud Detection Challenge\n",
    "https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection\n",
    "\n",
    "\n",
    "------------------\n",
    "\n",
    "\n",
    "### This notebook is meant to demo a hyper-param searching algos -- BayesianOptimization\n",
    "\n",
    "BayesianOptimization repo: [BayesianOptimization Github Link](https://github.com/fmfn/BayesianOptimization)\n",
    "\n",
    "Bayesian optimization works by constructing a posterior distribution of functions (gaussian process) that best describes the function you want to optimize. As the number of observations grows, the posterior distribution improves, and the algorithm becomes more certain of which regions in parameter space are worth exploring and which are not, as seen in the picture below.\n",
    "\n",
    "![BayesianOptimization in action](https://github.com/fmfn/BayesianOptimization/blob/master/examples/bo_example.png)\n",
    "\n",
    "As you iterate over and over, the algorithm balances its needs of exploration and exploitation taking into account what it knows about the target function. At each step a Gaussian Process is fitted to the known samples (points previously explored), and the posterior distribution, combined with a exploration strategy (such as UCB (Upper Confidence Bound), or EI (Expected Improvement)), are used to determine the next point that should be explored (see the gif below).\n",
    "\n",
    "![BayesianOptimization in action](https://github.com/fmfn/BayesianOptimization/blob/master/examples/bayesian_optimization.gif)\n",
    "\n",
    "This process is designed to minimize the number of steps required to find a combination of parameters that are close to the optimal combination. To do so, this method uses a proxy optimization problem (finding the maximum of the acquisition function) that, albeit still a hard problem, is cheaper (in the computational sense) and common tools can be employed. Therefore Bayesian Optimization is most adequate for situations where sampling the function to be optimized is a very expensive endeavor. See the references for a proper discussion of this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory in use before reading data: 0.10 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import gc\n",
    "# sklearn imports\n",
    "from sklearn.metrics.scorer import roc_auc_score\n",
    "import lightgbm\n",
    "# bayes_opt imports\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# memory\n",
    "process = psutil.Process(os.getpid())\n",
    "memused = process.memory_info().rss\n",
    "print('Total memory in use before reading data: {:.02f} GB'.format(memused/(2**30))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done data prep!!!\n",
      "Total memory in use after reading data: 26.62 GB \n"
     ]
    }
   ],
   "source": [
    "# # read data\n",
    "df_train = pd.read_hdf('../insample_iterations/insample_data/train.hdf').astype('float32')\n",
    "df_test = pd.read_hdf('../insample_iterations/insample_data/test.hdf').astype('float32')\n",
    "# col\n",
    "target = 'is_attributed'\n",
    "features = [\n",
    "    'app',\n",
    "    'device',\n",
    "    'os',\n",
    "    'channel',\n",
    "    'hour',\n",
    "    'in_test_hh',\n",
    "    'ip_day_hour_clicks',\n",
    "    'ip_app_day_hour_clicks',\n",
    "    'ip_os_day_hour_clicks',\n",
    "    'ip_device_day_hour_clicks',\n",
    "    'ip_day_test_hh_clicks',\n",
    "    'ip_app_device_clicks',\n",
    "    'ip_app_device_day_clicks',\n",
    "    'ip_day_nunique_app',\n",
    "    'ip_day_nunique_device',\n",
    "    'ip_day_nunique_channel',\n",
    "    'ip_day_nunique_hour',\n",
    "    'ip_nunique_app',\n",
    "    'ip_nunique_device',\n",
    "    'ip_nunique_channel',\n",
    "    'ip_nunique_hour',\n",
    "    'app_day_nunique_channel',\n",
    "    'app_nunique_channel',\n",
    "    'ip_app_day_nunique_os',\n",
    "    'ip_app_nunique_os',\n",
    "    'ip_device_os_day_nunique_app',\n",
    "    'ip_device_os_nunique_app',\n",
    "    'ip_app_day_var_hour',\n",
    "    'ip_device_day_var_hour',\n",
    "    'ip_os_day_var_hour',\n",
    "    'ip_channel_day_var_hour',\n",
    "    'ip_app_os_var_hour',\n",
    "    'ip_app_channel_var_day',\n",
    "    'ip_app_channel_mean_hour',\n",
    "    'ip_day_cumcount',\n",
    "    'ip_cumcount',\n",
    "    'ip_app_day_cumcount',\n",
    "    'ip_app_cumcount',\n",
    "    'ip_device_os_day_cumcount',\n",
    "    'ip_device_os_cumcount',\n",
    "    'next_click',\n",
    "    'previous_click',\n",
    "]\n",
    "# categorical\n",
    "categorical_features = [\n",
    "    'app',\n",
    "    'device',\n",
    "    'os',\n",
    "    'channel',\n",
    "    'hour',\n",
    "    'in_test_hh',\n",
    "]\n",
    "# prep data\n",
    "dtrain = lightgbm.Dataset(\n",
    "    df_train[features].values,\n",
    "    label=df_train[target].values,\n",
    "    feature_name=features,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=True,\n",
    ")\n",
    "dtest = lightgbm.Dataset(\n",
    "    df_test[features].values,\n",
    "    label=df_test[target].values,\n",
    "    feature_name=features,\n",
    "    categorical_feature=categorical_features\n",
    ")\n",
    "# cleanup\n",
    "del df_train\n",
    "gc.collect()\n",
    "print('done data prep!!!')\n",
    "# memory status\n",
    "memused = process.memory_info().rss\n",
    "print('Total memory in use after reading data: {:.02f} GB '\n",
    "      ''.format(memused / (2 ** 30)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Search Results Record\n",
    "-----------------------------------------------------\n",
    "\n",
    "| Time | Value | eta | n_rounds | num_leaves | max_depth | subsample | colsample_bytree| min_child_samples | scale_pos_weight |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "| 01m56s | 0.97951 | 0.3 | 25 | 54 | 8 | 0.9 | 1 | 100 | 100  \n",
    "| 01m50s | 0.97935 | 0.3 | 25 | 40 | 8 | 0.9 | 1 | 100 | 100  \n",
    "| 01m04s | 0.97431 | 0.3 | 25 | 4 | 5 | 0.9 | 0.6 | 100 | 100  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_depth |   num_leaves | \n",
      "    1 | 01m48s | \u001b[35m   0.97831\u001b[0m | \u001b[32m            0.7096\u001b[0m | \u001b[32m     4.3694\u001b[0m | \u001b[32m     29.0213\u001b[0m | \n",
      "    2 | 01m21s | \u001b[35m   0.97905\u001b[0m | \u001b[32m            0.8426\u001b[0m | \u001b[32m     4.7450\u001b[0m | \u001b[32m     47.2195\u001b[0m | \n",
      "    3 | 01m04s |    0.97431 |             0.6022 |      5.3822 |       4.0069 | \n",
      "    4 | 01m24s | \u001b[35m   0.97921\u001b[0m | \u001b[32m            0.9391\u001b[0m | \u001b[32m     5.5871\u001b[0m | \u001b[32m     22.1400\u001b[0m | \n",
      "    5 | 01m18s |    0.97793 |             0.5137 |      6.1553 |      12.8054 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:335: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\"Predicted variances smaller than 0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   max_depth |   num_leaves | \n",
      "    6 | 01m50s | \u001b[35m   0.97935\u001b[0m | \u001b[32m            0.9939\u001b[0m | \u001b[32m     7.9925\u001b[0m | \u001b[32m     39.8044\u001b[0m | \n",
      "    7 | 01m56s |    0.97925 |             0.9867 |      7.9415 |      63.9839 | \n",
      "    8 | 01m24s |    0.97807 |             0.9729 |      4.0254 |      63.8512 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ 0.00033154]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9 | 01m58s |    0.97930 |             0.5071 |      7.9855 |      55.2732 | \n",
      "   10 | 01m38s |    0.97881 |             0.9792 |      7.9976 |      18.8534 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -3.50464518e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 01m56s | \u001b[35m   0.97951\u001b[0m | \u001b[32m            0.9979\u001b[0m | \u001b[32m     7.9647\u001b[0m | \u001b[32m     53.6639\u001b[0m | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00037576]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 56, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   12 | 01m25s |    0.97824 |             0.9873 |      4.0340 |      14.9677 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -1.69967461e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13 | 01m54s |    0.97904 |             0.5082 |      7.9859 |      45.3286 | \n",
      "   14 | 01m54s |    0.97950 |             0.9992 |      6.9632 |      58.1132 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -1.51175600e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  8.59004549e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 54, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -2.55994300e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 4, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   15 | 01m54s |    0.97817 |             0.8539 |      7.1605 |      56.1544 | \n",
      "   16 | 01m21s |    0.97506 |             0.9605 |      7.9282 |       4.2543 | \n",
      "   17 | 01m26s |    0.97807 |             0.9989 |      4.0060 |      38.4673 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ 0.00152026]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 51, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   18 | 01m43s |    0.97947 |             0.9387 |      7.9877 |      28.7524 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([ -3.89689085e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 55, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19 | 01m26s |    0.97760 |             0.5070 |      4.0176 |      18.7738 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([  4.48329956e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 5, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20 | 01m59s |    0.97927 |             0.5428 |      7.9978 |      61.2742 | \n",
      "   21 | 01m26s |    0.97758 |             0.9929 |      4.0024 |       7.8988 | \n",
      "   22 | 01m51s |    0.97914 |             0.5017 |      7.9966 |      34.6797 | \n"
     ]
    }
   ],
   "source": [
    "def lightgbm_objective(num_leaves, max_depth, colsample_bytree):\n",
    "    lightgbm_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'learning_rate': 0.3,\n",
    "        'num_leaves': int(round(num_leaves, 0)),\n",
    "        'max_depth': int(round(max_depth, 0)),\n",
    "        'min_split_gain': 0,\n",
    "        'subsample': 0.9,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': round(colsample_bytree, 1),\n",
    "        'min_child_samples': 100,\n",
    "        'min_child_weight': 0,\n",
    "        'max_bin': 100,\n",
    "        'subsample_for_bin': 200000,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0,\n",
    "        'scale_pos_weight': 100,\n",
    "        'metric': 'auc',\n",
    "        'nthread': 22,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "    model = lightgbm.train(\n",
    "        params=lightgbm_params, \n",
    "        train_set=dtrain,\n",
    "        num_boost_round=25,\n",
    "        feature_name=features,\n",
    "        categorical_feature=categorical_features,\n",
    "        verbose_eval=1\n",
    "    )\n",
    "    proba = model.predict(df_test[features], num_iteration=model.best_iteration)\n",
    "    roc_score = roc_auc_score(y_true=df_test[target], y_score=proba)\n",
    "    return roc_score\n",
    "\n",
    "# A parameter grid for XGBoost\n",
    "params = {\n",
    "    'num_leaves': (4, 64),\n",
    "    'max_depth': (4, 8),\n",
    "    'colsample_bytree': (0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Initialize BO optimizer\n",
    "lightgbm_bayesopt = BayesianOptimization(\n",
    "    f=lightgbm_objective, \n",
    "    pbounds=params,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "# Maximize auc score\n",
    "lightgbm_bayesopt.maximize(init_points=5, n_iter=20)\n",
    "\n",
    "# get best param\n",
    "best_params = lightgbm_bayesopt.res['max']['max_params']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
